version: "3"

services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: backend
    network_mode: "host"
    volumes:
      - backend:/backend
    ports:
      - "8000:8000"
      - "5000:5000"
    environment:
      - DEBUG=1


  rabbit:
    container_name: rabbit
    hostname: rabbit
    image: rabbitmq:3.7.15-alpine
    network_mode: "host"
    environment:
      - RABBITMQ_DEFAULT_USER=admin
      - RABBITMQ_DEFAULT_PASS=CT2gNABH8eJ9yVh
    ports:
      - "5672:5672"

  whisper:
    image: "onerahmet/openai-whisper-asr-webservice:latest"
    network_mode: "host"
    environment:
      - ASR_MODEL=base
      - ASR_ENGINE=openai_whisper
    ports:
      - "9000:9000"
    depends_on:
      - backend

  llama:
    image: "ollama/ollama:latest"
    container_name: llama
    network_mode: "host"
    volumes:
      - model:/model
    ports:
      - "11434:11434"
    depends_on:
      - backend

volumes:
  model:
    driver: local
    driver_opts:
      type: 'none'
      o: 'bind'
      device: "$PWD/llama/model"
  backend:
    driver: local
