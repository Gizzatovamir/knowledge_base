version: "3"

services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: backend
    network_mode: "host"
    volumes:
      - backend:/backend
    ports:
      - "8000:8000"
      - "5000:5000"
      - "11434:11434"
      - "5672:5672"
    environment:
      - DEBUG=1
    depends_on:
      - rabbit
  rabbit:
    container_name: rabbit
    hostname: rabbit
    image: rabbitmq:3.7.15-alpine
    network_mode: "host"
    environment:
      - RABBITMQ_DEFAULT_USER=admin
      - RABBITMQ_DEFAULT_PASS=CT2gNABH8eJ9yVh
    ports:
      - "5672:5672"


  whisper:
    image: "onerahmet/openai-whisper-asr-webservice:latest"
    network_mode: "host"
    environment:
      - ASR_MODEL=base
      - ASR_ENGINE=openai_whisper
    ports:
      - 9000:9000
    depends_on:
      - backend

  llama:
    container_name: llama
    network_mode: "host"
    build:
      context: ./llama
      dockerfile: llama.Dockerfile
    volumes:
      - llama:/llama_root
    ports:
      - "11434:11434"
    depends_on:
      - backend

volumes:
  llama:
    driver: local
  backend:
    driver: local
